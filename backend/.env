# Provider-Agnostic AI Proxy Configuration
# Copy this file to .env and fill in your keys

# Option 1: OpenAI (Cloud - Best quality, costs money)
OPENAI_API_KEY=ssk-proj-d0T56JJlLVFDxaE_87BqG34oj_aiTGLPBpnWG_vbN0PJN-93pSIDBnRanPmRDgZ-PDCpm9y0VhT3BlbkFJpdrIoEjK5eNyMbYUw-miKX-K0bKRP1E-tqOmSQTxfeZvtZaYZaBowjKRdZt9a3JNygXebaIzcA

# Option 2: Anthropic (Cloud - Alternative to OpenAI)
ANTHROPIC_API_KEY=sk-ant-your-key-here

# Option 3: Ollama (Local - FREE, private, no API key needed!)
# Install: https://ollama.ai
# Then run: ollama pull llava
OLLAMA_ENDPOINT=http://localhost:11434/api/generate
OLLAMA_MODEL=llava

# You can use ANY combination:
# - OpenAI only (just set OPENAI_API_KEY)
# - Ollama only (install Ollama, leave API keys blank)
# - All three (browser UI lets you switch!)
# - Add your own provider (see backend/README.md)

